======================================================================
TRAINING REPORT: qwen-7b
======================================================================

MODEL INFORMATION
----------------------------------------------------------------------
Model Path: Qwen/Qwen2.5-7B-Instruct
Model Name: qwen-7b
Quantization: 4-bit
Model Vocab Size: 152,064
Tokenizer Vocab Size: 151,665
  âš  Mismatch: 399 tokens difference
Hidden Size: 3584
Number of Layers: 28
Attention Heads: 28

TRAINABLE PARAMETERS
----------------------------------------------------------------------
Trainable params: 1,090,199,040
All params: 4,352,972,288
Trainable %: 25.0449%
Frozen params: 3,262,773,248

TRAINING OVERVIEW
----------------------------------------------------------------------
Training Time: 2.00h
Total Steps: 149
Tokens/Second: 169.54
Samples/Second: 0.02

LOSS METRICS
----------------------------------------------------------------------
Final Train Loss: 1.0198
Final Eval Loss: 1.2460
Train-Val Gap: 0.2262 (22.18%)
Overfitting: Yes

CONVERGENCE
----------------------------------------------------------------------
Converged: Yes
Recent Improvement Rate: 0.03%
Recent Loss Std: 0.0343

GRADIENT STABILITY
----------------------------------------------------------------------
Mean Gradient Norm: 1.5162
Std Gradient Norm: 0.8498
Stability Score: 0.5604

LORA CONFIGURATION
----------------------------------------------------------------------
Rank (r): 16
Alpha: 32
Dropout: 0.05
Target Modules: q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj

LoRA Update Statistics:
  Mean Magnitude: 2.398133
  Max Magnitude: 8.198749
  Min Magnitude: 0.229292

DATASET INFORMATION
----------------------------------------------------------------------
Train Size: 7773
Eval Size: 864
Batch Size (effective): 16
Sequence Length: 512

GPU METRICS
----------------------------------------------------------------------
Peak VRAM: 14.64 GB
Mean VRAM: 14.64 GB

STABILITY
----------------------------------------------------------------------
NaN Detected: No
Divergence Detected: No
Training Stable: Yes

======================================================================
